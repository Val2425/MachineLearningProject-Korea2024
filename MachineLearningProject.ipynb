{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNyyMqHG8Fy8TOCA/Xhvv7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Val2425/MachineLearningProject-Korea2024/blob/main/MachineLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Introduction**\n"
      ],
      "metadata": {
        "id": "ReWUZrK0FDHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Purpose:**\n",
        "\n",
        "This project aims to classify news articles as real or fake using machine learning on textual content alone. Through natural language processing (NLP), we seek to detect misleading information—a crucial skill in today’s digital world.\n",
        "\n",
        "-\n",
        "\n",
        "**What is the Problem?**\n",
        "\n",
        "The rapid spread of fake news, especially via social media, poses significant risks to public opinion and social trust. This project focuses on distinguishing real from fake news articles, an issue highlighted by events like the American elections, where misinformation can heavily influence public sentiment.\n",
        "\n",
        "-\n",
        "\n",
        "**Why is This Problem Important?**\n",
        "\n",
        "Detecting fake news is both a timely and complex challenge. This project is intellectually engaging as it leverages NLP for a socially relevant task while remaining manageable within a binary classification framework.\n",
        "\n",
        "-\n",
        "\n",
        "**Expected Outcomes of the Model**\n",
        "\n",
        "Our objective is to develop a model with an F1-score of at least 0.85, balancing precision and recall to effectively minimize misclassifications. This metric underscores the model’s aim to accurately identify fake news while reducing errors, aligning with the critical nature of the task."
      ],
      "metadata": {
        "id": "1qdoWsh5Gcm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Methods**"
      ],
      "metadata": {
        "id": "h9-9AV2bF2Qt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 Import dataset from Kaggle**"
      ],
      "metadata": {
        "id": "OpBTd7CgGohy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decided to use the \"Fake News Detection\" datataset ([Link to the dataset](https://www.kaggle.com/datasets/bhavikjikadara/fake-news-detection))"
      ],
      "metadata": {
        "id": "0_B3oRgrHRSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we download our personal kaggle API key on our computer. Then we add it the the google colab files :"
      ],
      "metadata": {
        "id": "AGwjeuZPCKil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "del uploaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "wrUiM_5bGdzj",
        "outputId": "81fc507d-ec5e-4f61-e684-dfbf06c5581a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e8d9e1c2-c840-40bb-b19d-8633696fdcbe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e8d9e1c2-c840-40bb-b19d-8633696fdcbe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a kaggle folder and copy kaggle.json to the folder created and give permission for the json to act"
      ],
      "metadata": {
        "id": "rXtTzFayJ7kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create folder\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "#copy kaggle.json to folder\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "#permission\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Km6a_Cp5KEO7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then paste to code given when we click on the download button for the dataset on the kaggle website"
      ],
      "metadata": {
        "id": "VybVhUGcMfEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"bhavikjikadara/fake-news-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gU3iwmkZLv4M",
        "outputId": "7c33532a-a36b-479a-def7-e25b8c32398c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/bhavikjikadara/fake-news-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41.0M/41.0M [00:00<00:00, 47.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then change directory to be in the file with the two files"
      ],
      "metadata": {
        "id": "QSxyPjBhOzF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1RjBBXhN8Sf",
        "outputId": "927dc7b4-2963-4f3b-c298-6ab728645e3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.2 Dataset Description**"
      ],
      "metadata": {
        "id": "OKZihICL_FGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of the dataset"
      ],
      "metadata": {
        "id": "_rToystV_Rs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3 Data Preprocessing**"
      ],
      "metadata": {
        "id": "STLkTp2ITA4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "true_df = pd.read_csv('true.csv')\n",
        "fake_df = pd.read_csv('fake.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oKztIo5iTlU9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3.1 Initial cleaning**"
      ],
      "metadata": {
        "id": "NAC5dSaYQVlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some dates from fake.csv contain month that are written with three letters (ex : Nov)\n",
        "# Replacing abbreviation to have a uniform format for dates\n",
        "mois = {\n",
        "    'Jan ': 'January ',\n",
        "    'Feb ': 'February ',\n",
        "    'Mar ': 'March ',\n",
        "    'Apr ': 'April ',\n",
        "    'May ': 'May ',\n",
        "    'Jun ': 'June ',\n",
        "    'Jul ': 'July ',\n",
        "    'Aug ': 'August ',\n",
        "    'Sep ': 'September ',\n",
        "    'Oct ': 'October ',\n",
        "    'Nov ': 'November ',\n",
        "    'Dec ': 'December '\n",
        "}\n",
        "fake_df['date'] = fake_df['date'].replace(mois, regex=True)"
      ],
      "metadata": {
        "id": "jMtS9i62q3h6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We then convert dates to Date variables\n",
        "true_df['date'] = pd.to_datetime(true_df['date'], errors='coerce')\n",
        "fake_df['date'] = pd.to_datetime(fake_df['date'], errors='coerce')"
      ],
      "metadata": {
        "id": "s-EudKmhsHtA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count missing values\n",
        "print(true_df.isnull().sum())\n",
        "print()\n",
        "print(fake_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVVZ5ROog_C3",
        "outputId": "70831439-7488-4e0e-e71f-6c8f74a8552d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title      0\n",
            "text       0\n",
            "subject    0\n",
            "date       0\n",
            "dtype: int64\n",
            "\n",
            "title       0\n",
            "text        0\n",
            "subject     0\n",
            "date       45\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After conversion and replacement of the abbreviation, we find 45 null values in fake_df. 45 is a low number so we will just erase them"
      ],
      "metadata": {
        "id": "w47GGUAJt6nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Erase null values in fake_df\n",
        "fake_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "2TfRqs8QuPNn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See how many duplicates there are in each dataset\n",
        "\n",
        "duplicates = true_df.duplicated().sum()\n",
        "print(duplicates)\n",
        "\n",
        "duplicates = fake_df.duplicated().sum()\n",
        "print(duplicates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oUTMTJDgC5o6",
        "outputId": "8c87b886-6c22-4b8d-f939-b28c52270a45"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we erase the duplicates to keep only one occurence"
      ],
      "metadata": {
        "id": "0-yLuhJZHU9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Erase duplicates\n",
        "true_df.drop_duplicates(keep='first', inplace=True)\n",
        "fake_df.drop_duplicates(keep='first', inplace=True)"
      ],
      "metadata": {
        "id": "0Tnnjl--HRJN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informations about the dataset\n",
        "print(true_df.info())\n",
        "print()\n",
        "print(fake_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMtfhIiYXiAO",
        "outputId": "b55e33f6-1690-4782-a6f1-7699f26e60ef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 21211 entries, 0 to 21416\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype         \n",
            "---  ------   --------------  -----         \n",
            " 0   title    21211 non-null  object        \n",
            " 1   text     21211 non-null  object        \n",
            " 2   subject  21211 non-null  object        \n",
            " 3   date     21211 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(3)\n",
            "memory usage: 828.6+ KB\n",
            "None\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 23433 entries, 0 to 23480\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype         \n",
            "---  ------   --------------  -----         \n",
            " 0   title    23433 non-null  object        \n",
            " 1   text     23433 non-null  object        \n",
            " 2   subject  23433 non-null  object        \n",
            " 3   date     23433 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(3)\n",
            "memory usage: 915.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a sample of the dataset\n",
        "print(true_df.sample(5))\n",
        "print()\n",
        "print(fake_df.sample(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NWs4rMHbXrNs",
        "outputId": "11f18e07-de06-4c5f-e795-03f8a6b59f8b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  title  \\\n",
            "5275  In sweeping move, Trump puts regulation monito...   \n",
            "6380  Tillerson says China should be barred from Sou...   \n",
            "6372  AT&T chief executive, Trump meet amid planned ...   \n",
            "3872    Senate votes to confirm Gottlieb as head of FDA   \n",
            "9112  Clinton would use executive action to end tax ...   \n",
            "\n",
            "                                                   text       subject  \\\n",
            "5275   President Donald Trump signed an executive or...  politicsNews   \n",
            "6380   U.S. President-elect Donald Trump’s nominee f...  politicsNews   \n",
            "6372   AT&T Inc (T.N) Chief Executive Randall Stephe...  politicsNews   \n",
            "3872   The U.S. Senate voted on Tuesday to confirm D...  politicsNews   \n",
            "9112   U.S. Democratic presidential candidate Hillar...  politicsNews   \n",
            "\n",
            "           date  \n",
            "5275 2017-02-24  \n",
            "6380 2017-01-11  \n",
            "6372 2017-01-12  \n",
            "3872 2017-05-09  \n",
            "9112 2016-06-15  \n",
            "\n",
            "                                                   title  \\\n",
            "12930  KEITH SCOTT’S BROTHER Tells Charlotte Reporter...   \n",
            "18947  BREAKING: STARBUCKS CEO To Step Down After Ple...   \n",
            "7637    This New Ad Gives Us A Horrifyingly Realistic...   \n",
            "12343  NBA CRYBABY COACH Worries About President-Elec...   \n",
            "14012  DISGUSTING! Hillary Voters Taunt And Abuse Ame...   \n",
            "\n",
            "                                                    text    subject       date  \n",
            "12930  The first Black (and half White) President has...   politics 2016-09-23  \n",
            "18947  The arrogance of a CEO of a major company like...  left-news 2017-03-19  \n",
            "7637   Republican presidential frontrunner Donald Tru...       News 2016-03-07  \n",
            "12343   It turns out the hypocrite, liberal, Golden S...   politics 2016-11-20  \n",
            "14012  Crazy mob vandalizes, threatens, and spits at ...   politics 2016-04-30  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that true_df text column contains \"(Reuters) - \" that can cause overfitting. So we have to delete it."
      ],
      "metadata": {
        "id": "qR6CEPtzaFrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all text until \"(Reuters) - \" in true_df\n",
        "true_df['text'] = true_df['text'].str.replace(r'^.*\\(Reuters\\) - ', '', regex=True)"
      ],
      "metadata": {
        "id": "Aofj8SuDZvHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.4 Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "6j8IU0Gj-fuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistics\n",
        "print(true_df.describe())\n",
        "print()\n",
        "print(fake_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbPSvsfMhIkr",
        "outputId": "2e77e220-9907-492b-ce76-bf3ad2c8ae5a",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                date\n",
            "count                          21211\n",
            "mean   2017-06-02 21:00:01.527509248\n",
            "min              2016-01-13 00:00:00\n",
            "25%              2017-01-27 00:00:00\n",
            "50%              2017-09-12 00:00:00\n",
            "75%              2017-11-02 00:00:00\n",
            "max              2017-12-31 00:00:00\n",
            "\n",
            "                                date\n",
            "count                          23433\n",
            "mean   2016-10-07 05:42:54.062220032\n",
            "min              2015-03-31 00:00:00\n",
            "25%              2016-04-06 00:00:00\n",
            "50%              2016-10-14 00:00:00\n",
            "75%              2017-04-14 00:00:00\n",
            "max              2017-12-31 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of true and false articles is pretty even (47,7% - 52,3%), it's good for a binary classification."
      ],
      "metadata": {
        "id": "PUchOM_tG39V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse the length of\n",
        "print(true_df['title'].apply(len).describe())\n",
        "print()\n",
        "print(fake_df['title'].apply(len).describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZEdg8qRLlot",
        "outputId": "6afe6058-995d-47d2-df53-b3a69e770090"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    21211.000000\n",
            "mean        64.658291\n",
            "std          9.162659\n",
            "min         26.000000\n",
            "25%         59.000000\n",
            "50%         64.000000\n",
            "75%         70.000000\n",
            "max        133.000000\n",
            "Name: title, dtype: float64\n",
            "\n",
            "count    23433.000000\n",
            "mean        94.187599\n",
            "std         27.173264\n",
            "min         15.000000\n",
            "25%         77.000000\n",
            "50%         90.000000\n",
            "75%        105.000000\n",
            "max        286.000000\n",
            "Name: title, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0POtoENHMA0c"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}