{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMC6nJ3GNlaGra0X2stiz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Val2425/MachineLearningProject-Korea2024/blob/main/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Import Data**"
      ],
      "metadata": {
        "id": "2PAeJjk2AAkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import dataset from Kaggle\n",
        "from google.colab import files\n",
        "\n",
        "# Upload Kaggle API key file (kaggle.json)\n",
        "uploaded = files.upload()\n",
        "del uploaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RWVjxF0g26dx",
        "outputId": "b6c7e34b-e3e8-4803-f487-9ee661c91194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86b31f87-e060-48a0-93f2-1558d630155e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86b31f87-e060-48a0-93f2-1558d630155e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBs-NyjpwWWc",
        "outputId": "7cb72639-19d6-4c2e-f5c1-9ccc03236fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Configure Kaggle API credentials\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset using Kaggle API\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"bhavikjikadara/fake-news-detection\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIVf0h8Q23d6",
        "outputId": "a5d7ba6d-4a35-4d78-b79a-49aa151c601a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load true and fake news datasets\n",
        "true_df = pd.read_csv('true.csv')\n",
        "fake_df = pd.read_csv('fake.csv')"
      ],
      "metadata": {
        "id": "g4gzuBpJwhnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing abbreviation to have a uniform format for dates\n",
        "mois = {\n",
        "    'Jan ': 'January ',\n",
        "    'Feb ': 'February ',\n",
        "    'Mar ': 'March ',\n",
        "    'Apr ': 'April ',\n",
        "    'May ': 'May ',\n",
        "    'Jun ': 'June ',\n",
        "    'Jul ': 'July ',\n",
        "    'Aug ': 'August ',\n",
        "    'Sep ': 'September ',\n",
        "    'Oct ': 'October ',\n",
        "    'Nov ': 'November ',\n",
        "    'Dec ': 'December '\n",
        "}\n",
        "fake_df['date'] = fake_df['date'].replace(mois, regex=True)\n",
        "\n",
        "# Converting dates to Date variables\n",
        "true_df['date'] = pd.to_datetime(true_df['date'], errors='coerce')\n",
        "fake_df['date'] = pd.to_datetime(fake_df['date'], errors='coerce')\n",
        "\n",
        "print(true_df['date'].sample(10))\n",
        "print(fake_df['date'].sample(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRSjh24Oxd8J",
        "outputId": "2f8cc799-a83a-4822-8f57-3cefd90f4e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9532    2016-05-16\n",
            "18214   2017-10-05\n",
            "12889   2017-12-07\n",
            "3800    2017-05-12\n",
            "20543   2017-09-09\n",
            "13776   2017-11-27\n",
            "20290   2017-09-11\n",
            "8761    2016-07-13\n",
            "10717   2016-02-23\n",
            "19885   2017-09-16\n",
            "Name: date, dtype: datetime64[ns]\n",
            "12132   2016-12-15\n",
            "73      2017-11-22\n",
            "1032    2017-06-23\n",
            "15007   2015-10-29\n",
            "6079    2016-06-01\n",
            "5486    2016-07-13\n",
            "7024    2016-04-08\n",
            "6361    2016-05-15\n",
            "3810    2016-11-14\n",
            "4058    2016-10-24\n",
            "Name: date, dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a label column: 1 for true news, 0 for fake news\n",
        "true_df['label'] = 1\n",
        "fake_df['label'] = 0\n",
        "\n",
        "# Combine both datasets into a single DataFrame\n",
        "df = pd.concat([true_df, fake_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "UBm7L4iDx_-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Date column**"
      ],
      "metadata": {
        "id": "pAV4pc0k_2ss"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjT-UyefC8Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Subject column**"
      ],
      "metadata": {
        "id": "LpbbKp6cAPSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the 'subject' column across datasets\n",
        "subject_mapping = {\n",
        "    'News': 'General News',\n",
        "    'US_News': 'General News',\n",
        "    'worldnews': 'General News',\n",
        "    'politics': 'Politics',\n",
        "    'politicsNews': 'Politics',\n",
        "    'left-news': 'Politics',\n",
        "    'Middle-east': 'General News',\n",
        "    'Government News': 'Politics'\n",
        "}\n",
        "df['subject'] = df['subject'].map(subject_mapping)\n",
        "\n",
        "# Drop the 'subject' column because it is not relevant for the analysis\n",
        "df = df.drop(columns=['subject'])"
      ],
      "metadata": {
        "id": "a6IC0THgx-3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Feature engineering**"
      ],
      "metadata": {
        "id": "4a4y-pdhA2YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate uppercase letter percentage in text with rounding to 2 decimal places\n",
        "def calculate_uppercase_proportion(text):\n",
        "    if len(text) == 0:\n",
        "        return 0\n",
        "    uppercase_count = sum(1 for char in text if char.isupper())\n",
        "    percentage = (uppercase_count / len(text))\n",
        "    return round(percentage, 3)  # Round to two decimal places\n",
        "\n",
        "# Add a column for uppercase percentage in titles\n",
        "df['uppercase_proportion'] = df['title'].apply(calculate_uppercase_proportion)"
      ],
      "metadata": {
        "id": "uEQcnbw_zRZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Title and Text columns**"
      ],
      "metadata": {
        "id": "r-hoYURRA8MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all text until \"(Reuters) - \" in the dataset\n",
        "df['text'] = df['text'].str.replace(r'^.*\\(Reuters\\) - ', '', regex=True)\n",
        "\n",
        "# Convert text to lowercase and strip whitespace\n",
        "df['title'] = df['title'].str.lower().str.strip()\n",
        "df['text'] = df['text'].str.lower().str.strip()\n",
        "\n",
        "# Ensure no NaN values in 'title' and 'text' before removing special characters\n",
        "df['title'] = df['title'].fillna('').str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)\n",
        "df['text'] = df['text'].fillna('').str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)\n",
        "\n",
        "# Ensure no multiple spaces in the text and rejoin into sentences\n",
        "df['title'] = df['title'].str.split().str.join(' ')\n",
        "df['text'] = df['text'].str.split().str.join(' ')\n",
        "\n",
        "# Remove duplicates from the combined DataFrame\n",
        "df.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "# Remove rows where 'title' or 'text' are empty strings\n",
        "df = df[(df['title'] != '') & (df['text'] != '')]"
      ],
      "metadata": {
        "id": "e1EvDiRbyzjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.sample(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k82pYM6s3Ik8",
        "outputId": "f0eabb2a-c927-4ad0-8ded-b521c48a159f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   title  \\\n",
            "37042  federally funded riot baltimore mayor wants fe...   \n",
            "43487  nothing big mac donald trump jr caught in late...   \n",
            "36165  will hillary s secret weapon be a game changer...   \n",
            "35448  the truth about why hillary is the only candid...   \n",
            "30956  pam geller rips into geraldo for insults about...   \n",
            "6598   mistrial declared in corruption case against e...   \n",
            "6722   trump s tough trade talk makes u s firms fear ...   \n",
            "37623  bam commie scammer mustafa ali the epa s envir...   \n",
            "198    senator grassley expresses reservations on two...   \n",
            "27740  noam chomsky warns americans the gop is the mo...   \n",
            "3116   senate s mcconnell draft healthcare bill expec...   \n",
            "20808  after year of repression in bahrain west remai...   \n",
            "29374  trump dominates south carolina dooming the rep...   \n",
            "43437  syria north korea trump s axis of evil is bigg...   \n",
            "2395   trump administration reaches deal with texas c...   \n",
            "10068  pentagon chief wants streamlined more nimble u...   \n",
            "7434   republicans gain governorships but north carol...   \n",
            "34941  day after dallas cops memorial obama invites b...   \n",
            "21977  trump lashes out at ceos suggests he ll replac...   \n",
            "5077   trump says he s sure senator paul will back re...   \n",
            "\n",
            "                                                    text       date  label  \\\n",
            "37042  after giving room to destroy baltimore s mayor... 2015-05-29      0   \n",
            "43487  patrick henningsen 21st century wiredespite re... 2017-07-13      0   \n",
            "36165  so bill clinton wants a third term so much tha... 2015-12-25      0   \n",
            "35448  this news should be enough to end hillary s ob... 2016-04-27      0   \n",
            "30956  pam geller is not the person you d ever want t... 2017-11-01      0   \n",
            "6598   a federal judge declared a mistrial on thursda... 2016-12-22      1   \n",
            "6722   u s president elect donald trump s challenges ... 2016-12-12      1   \n",
            "37623  we hope scott pruitt is busy bidding a large s... 2017-03-12      0   \n",
            "198    the republican chairman of the u s senate comm... 2017-12-12      1   \n",
            "27740  noam chomsky desperately wants america to wake... 2016-05-17      0   \n",
            "3116   u s senate republicans will release the text o... 2017-06-20      1   \n",
            "20808  bahrain s government has crushed dissent and v... 2017-09-07      1   \n",
            "29374  iiiiiitttt ssssssss a wonderful day in the whi... 2016-02-21      0   \n",
            "43437  whitney webb mint pressbush s axis of evil spe... 2017-08-25      0   \n",
            "2395   u s immigration authorities signed deals on mo... 2017-07-31      1   \n",
            "10068  u s defense secretary ash carter on tuesday ca... 2016-04-05      1   \n",
            "7434   republicans extended their majority of u s gov... 2016-11-08      1   \n",
            "34941  when america elected a community agitator they... 2016-07-13      0   \n",
            "21977  donald trump attacked the ceos who are leaving... 2017-08-15      0   \n",
            "5077   u s president donald trump said on twitter on ... 2017-03-08      1   \n",
            "\n",
            "       uppercase_proportion  \n",
            "37042                 0.793  \n",
            "43487                 0.294  \n",
            "36165                 0.167  \n",
            "35448                 0.386  \n",
            "30956                 0.232  \n",
            "6598                  0.045  \n",
            "6722                  0.062  \n",
            "37623                 0.264  \n",
            "198                   0.045  \n",
            "27740                 0.210  \n",
            "3116                  0.085  \n",
            "20808                 0.056  \n",
            "29374                 0.131  \n",
            "43437                 0.250  \n",
            "2395                  0.029  \n",
            "10068                 0.043  \n",
            "7434                  0.047  \n",
            "34941                 0.333  \n",
            "21977                 0.195  \n",
            "5077                  0.061  \n"
          ]
        }
      ]
    }
  ]
}