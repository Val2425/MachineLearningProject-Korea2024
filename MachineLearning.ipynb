{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Val2425/MachineLearningProject-Korea2024/blob/main/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PAeJjk2AAkl"
      },
      "source": [
        "#**1. Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RWVjxF0g26dx",
        "outputId": "655c5ef5-f0c0-495d-de61-552659c0cd6e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a0b25e82-d627-49f8-b8db-4fca5c42bf92\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a0b25e82-d627-49f8-b8db-4fca5c42bf92\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "#Import dataset from Kaggle\n",
        "from google.colab import files\n",
        "\n",
        "# Upload Kaggle API key file (kaggle.json)\n",
        "uploaded = files.upload()\n",
        "del uploaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBs-NyjpwWWc",
        "outputId": "cde6029f-cf85-4f8e-9385-27d99b019b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/bhavikjikadara/fake-news-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41.0M/41.0M [00:00<00:00, 112MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Configure Kaggle API credentials\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset using Kaggle API\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"bhavikjikadara/fake-news-detection\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIVf0h8Q23d6",
        "outputId": "cbb7cb87-30ae-46b8-f7e2-21f34b679819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "cd /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g4gzuBpJwhnT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load true and fake news datasets\n",
        "true_df = pd.read_csv('true.csv')\n",
        "fake_df = pd.read_csv('fake.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRSjh24Oxd8J",
        "outputId": "ca802bf9-361f-4448-fd6f-bfbdb92d075a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11233   2016-01-14\n",
            "8200    2016-09-12\n",
            "16975   2017-10-19\n",
            "13409   2017-11-30\n",
            "12510   2017-12-11\n",
            "1209    2017-10-16\n",
            "17725   2017-10-11\n",
            "12115   2017-12-16\n",
            "10020   2016-04-01\n",
            "823     2017-11-05\n",
            "Name: date, dtype: datetime64[ns]\n",
            "11785   2017-01-29\n",
            "9215    2017-12-12\n",
            "5383    2016-07-21\n",
            "16105   2017-05-10\n",
            "16504   2016-07-10\n",
            "18383   2017-07-05\n",
            "21449   2015-09-21\n",
            "20835   2016-03-21\n",
            "6462    2016-05-09\n",
            "9760    2017-10-03\n",
            "Name: date, dtype: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "# Replacing abbreviation to have a uniform format for dates\n",
        "mois = {\n",
        "    'Jan ': 'January ',\n",
        "    'Feb ': 'February ',\n",
        "    'Mar ': 'March ',\n",
        "    'Apr ': 'April ',\n",
        "    'May ': 'May ',\n",
        "    'Jun ': 'June ',\n",
        "    'Jul ': 'July ',\n",
        "    'Aug ': 'August ',\n",
        "    'Sep ': 'September ',\n",
        "    'Oct ': 'October ',\n",
        "    'Nov ': 'November ',\n",
        "    'Dec ': 'December '\n",
        "}\n",
        "fake_df['date'] = fake_df['date'].replace(mois, regex=True)\n",
        "\n",
        "# Converting dates to Date variables\n",
        "true_df['date'] = pd.to_datetime(true_df['date'], errors='coerce')\n",
        "fake_df['date'] = pd.to_datetime(fake_df['date'], errors='coerce')\n",
        "\n",
        "print(true_df['date'].sample(10))\n",
        "print(fake_df['date'].sample(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UBm7L4iDx_-q"
      },
      "outputs": [],
      "source": [
        "# Add a label column: 1 for true news, 0 for fake news\n",
        "true_df['label'] = 1\n",
        "fake_df['label'] = 0\n",
        "\n",
        "# Combine both datasets into a single DataFrame\n",
        "df = pd.concat([true_df, fake_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAV4pc0k_2ss"
      },
      "source": [
        "#**2. Date column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yjT-UyefC8Wz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpbbKp6cAPSl"
      },
      "source": [
        "#**3. Subject column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a6IC0THgx-3b"
      },
      "outputs": [],
      "source": [
        "# Standardize the 'subject' column across datasets\n",
        "subject_mapping = {\n",
        "    'News': 'General News',\n",
        "    'US_News': 'General News',\n",
        "    'worldnews': 'General News',\n",
        "    'politics': 'Politics',\n",
        "    'politicsNews': 'Politics',\n",
        "    'left-news': 'Politics',\n",
        "    'Middle-east': 'General News',\n",
        "    'Government News': 'Politics'\n",
        "}\n",
        "df['subject'] = df['subject'].map(subject_mapping)\n",
        "\n",
        "# Drop the 'subject' column because it is not relevant for the analysis\n",
        "df = df.drop(columns=['subject'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a4y-pdhA2YE"
      },
      "source": [
        "#**4. Feature engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uEQcnbw_zRZW"
      },
      "outputs": [],
      "source": [
        "# Function to calculate uppercase letter percentage in text with rounding to 2 decimal places\n",
        "def calculate_uppercase_proportion(text):\n",
        "    if len(text) == 0:\n",
        "        return 0\n",
        "    uppercase_count = sum(1 for char in text if char.isupper())\n",
        "    percentage = (uppercase_count / len(text))\n",
        "    return round(percentage, 3)  # Round to two decimal places\n",
        "\n",
        "# Add a column for uppercase percentage in titles\n",
        "df['uppercase_proportion'] = df['title'].apply(calculate_uppercase_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JmIkPWg8UnmA"
      },
      "outputs": [],
      "source": [
        "# Given the different features of the dataset, we will not be using this feature to train the dataset. It is more a tool to gain some insight about the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-hoYURRA8MJ"
      },
      "source": [
        "#**5. Title and Text columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "idYEQ5ehQS1w",
        "outputId": "b2436371-a02e-45bb-f308-36668afaf93e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df['text'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V929WELMFnnd"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates from the combined DataFrame\n",
        "df.drop_duplicates(keep='first', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pxLxJYfRFa1w"
      },
      "outputs": [],
      "source": [
        "# Delete all text until \"(Reuters) - \" in the dataset\n",
        "df['text'] = df['text'].str.replace(r'^.*\\(Reuters\\) - ', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CKDorsI7PYtF"
      },
      "outputs": [],
      "source": [
        "# Convert to lowercase\n",
        "df['title'] = df['title'].str.lower()\n",
        "df['text'] = df['text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DE-mJZosGwaf"
      },
      "outputs": [],
      "source": [
        "# Replace only '.' with '' in the 'text' column\n",
        "df['title'] = df['title'].str.replace(r'\\.', '', regex=True)\n",
        "df['text'] = df['text'].str.replace(r'\\.', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C7iZ3mRRFhX2"
      },
      "outputs": [],
      "source": [
        "# Ensure no NaN values in 'title' and 'text' before removing special characters\n",
        "df['title'] = df['title'].fillna('').str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)\n",
        "df['text'] = df['text'].fillna('').str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e1EvDiRbyzjD"
      },
      "outputs": [],
      "source": [
        "# Remove rows where 'title' or 'text' are empty strings\n",
        "df = df[(df['title'] != '') & (df['text'] != '')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elTs8P9MzXP7",
        "outputId": "2aaa12e6-22d7-4413-f5c6-706f410e1cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "df['title'] = df['title'].apply(word_tokenize)\n",
        "df['text'] = df['text'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjs98AsTCrkK",
        "outputId": "d9fa41ee-c0b7-400f-99dd-b946dd836eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['title'] = df['title'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "df['text'] = df['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0t_Mh8SBZxZ",
        "outputId": "198711b3-bafa-491a-d3e2-b2114e5eb3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Removing stop words\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['title'] = df['title'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stop_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hQYFQNjrKflv"
      },
      "outputs": [],
      "source": [
        "# Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_title = vectorizer.fit_transform(df['title'].apply(' '.join))\n",
        "X_text = vectorizer.fit_transform(df['text'].apply(' '.join))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxXnq1DPY6wi"
      },
      "source": [
        "#**6. Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hsHdGb0KYSlR"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.sparse import hstack\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import classification_report, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "znw_GVecYn1G"
      },
      "outputs": [],
      "source": [
        "# Separate X and Y\n",
        "X = hstack((X_title, X_text))\n",
        "Y = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gfip4MB_Dg4n"
      },
      "outputs": [],
      "source": [
        "# Split the data into train + validation and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AkKfQ5WkZdoK"
      },
      "outputs": [],
      "source": [
        "#param_grid = {\n",
        "#    'n_estimators': [50, 100, 200, 300],          # Number of trees\n",
        "#    'max_depth': [10, 20, 30, None],              # Maximum depth of the tree\n",
        "#    'min_samples_split': [2, 5, 10],              # Minimum samples required to split a node\n",
        "#    'min_samples_leaf': [1, 2, 4],                # Minimum samples required at a leaf node\n",
        "#    'bootstrap': [True, False],                   # Use bootstrap samples\n",
        "#}\n",
        "#\n",
        "## Initialize the Random Forest Classifier\n",
        "#rf = RandomForestClassifier(random_state=42)\n",
        "#\n",
        "## Perform Randomized Search with cross-validation\n",
        "#random_search = RandomizedSearchCV(\n",
        "#    estimator=rf,\n",
        "#    param_distributions=param_grid,\n",
        "#    n_iter=50,                                    # Number of parameter combinations to try\n",
        "#    cv=3,                                         # 3-fold cross-validation\n",
        "#    n_jobs=-1,                                    # Use all available CPU cores\n",
        "#    verbose=2,                                    # Print progress\n",
        "#    random_state=42,                              # Ensure reproducibility\n",
        "#    scoring='f1',                                 # Optimize for F1-score\n",
        "#)\n",
        "#\n",
        "## Fit the Randomized Search model\n",
        "#random_search.fit(X_train, y_train)\n",
        "#\n",
        "## Get the best parameters and model\n",
        "#best_params = random_search.best_params_\n",
        "#best_rf = random_search.best_estimator_\n",
        "#\n",
        "#print(\"Best parameters found: \", best_params)\n",
        "#\n",
        "## Evaluate the tuned model on the test set\n",
        "#y_pred = best_rf.predict(X_test)\n",
        "#\n",
        "## Calculate metrics\n",
        "#accuracy = accuracy_score(y_test, y_pred)\n",
        "#f1 = f1_score(y_test, y_pred, average='binary')\n",
        "#\n",
        "#print(\"Tuned Model Accuracy:\", accuracy)\n",
        "#print(\"Tuned Model F1 Score:\", f1)\n",
        "#print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5S_EQ9G9DHB",
        "outputId": "19257ddf-e8a6-4685-d54d-a87355966809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'kernel': 'rbf', 'gamma': 0.1, 'degree': 3, 'C': 10}\n",
            "\n",
            "Validation Results:\n",
            "Recall (Class 0): 0.9853780313837375\n",
            "Validation Accuracy: 0.9910514541387024\n",
            "Validation F1 Score: 0.9919238534756274\n",
            "\n",
            "Validation Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      2804\n",
            "           1       0.99      1.00      0.99      3454\n",
            "\n",
            "    accuracy                           0.99      6258\n",
            "   macro avg       0.99      0.99      0.99      6258\n",
            "weighted avg       0.99      0.99      0.99      6258\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import recall_score, f1_score, classification_report\n",
        "\n",
        "# Define the parameter grid for SVM tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],                # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf', 'poly'],   # Kernel types\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],  # Kernel coefficient\n",
        "    'degree': [2, 3, 4]                    # Degree of polynomial kernel (for 'poly')\n",
        "}\n",
        "\n",
        "# Instantiate the SVM model\n",
        "svm_clf = SVC()\n",
        "\n",
        "# Set up the RandomizedSearchCV for hyperparameter tuning\n",
        "svm_tuner = RandomizedSearchCV(\n",
        "    estimator=svm_clf,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=15,              # Number of parameter combinations to try\n",
        "    cv=3,                   # 3-fold cross-validation\n",
        "    scoring='f1',           # Optimize for F1 score\n",
        "    verbose=2,              # Verbose output\n",
        "    random_state=42,\n",
        "    n_jobs=-1               # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit the tuner on the training data\n",
        "svm_tuner.fit(X_train, y_train)\n",
        "\n",
        "# Display the best parameters\n",
        "print(\"Best parameters found:\", svm_tuner.best_params_)\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "best_svm = svm_tuner.best_estimator_\n",
        "y_val_pred = best_svm.predict(X_val)\n",
        "\n",
        "val_recall = recall_score(y_val, y_val_pred, pos_label=0)\n",
        "val_f1 = f1_score(y_val, y_val_pred, average='binary')\n",
        "val_accuracy = best_svm.score(X_val, y_val)\n",
        "\n",
        "print(\"\\nValidation Results:\")\n",
        "print(f\"Recall (Class 0): {val_recall}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "print(f\"Validation F1 Score: {val_f1}\")\n",
        "print(\"\\nValidation Set Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Final evaluation on the test set\n",
        "y_test_pred = best_svm.predict(X_test)\n",
        "\n",
        "test_recall = recall_score(y_test, y_test_pred, pos_label=0)\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='binary')\n",
        "test_accuracy = best_svm.score(X_test, y_test)\n",
        "test_cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nTest Results:\")\n",
        "print(f\"Recall (Class 0): {test_recall}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test F1 Score: {test_f1}\")\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(test_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhqRiJsPffpE",
        "outputId": "9a6da42b-d483-463f-c9a5-a760855fc4ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Results:\n",
            "Recall (Class 0): 0.9855715871254163\n",
            "Test Accuracy: 0.9897724367169521\n",
            "Test F1 Score: 0.9905437352245863\n",
            "\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      3604\n",
            "           1       0.99      0.99      0.99      4218\n",
            "\n",
            "    accuracy                           0.99      7822\n",
            "   macro avg       0.99      0.99      0.99      7822\n",
            "weighted avg       0.99      0.99      0.99      7822\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3552   52]\n",
            " [  28 4190]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(best_svm, 'best_svm_model.pkl')\n",
        "\n",
        "# Load the model (example)\n",
        "loaded_model = joblib.load('best_svm_model.pkl')"
      ],
      "metadata": {
        "id": "vBUnSGTwf1D0"
      },
      "execution_count": 28,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyPP39VqqTk5CJ2ZMGCs1X0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}