{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOu1BitE/IPMQldvsYoq0ME",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Val2425/MachineLearningProject-Korea2024/blob/main/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Import Data**"
      ],
      "metadata": {
        "id": "2PAeJjk2AAkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import dataset from Kaggle\n",
        "from google.colab import files\n",
        "\n",
        "# Upload Kaggle API key file (kaggle.json)\n",
        "uploaded = files.upload()\n",
        "del uploaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RWVjxF0g26dx",
        "outputId": "5dddb27a-2cb1-48c1-e1f5-71a6b6e8f3d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5a03087-da28-4c8a-992e-465283ebd65d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5a03087-da28-4c8a-992e-465283ebd65d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBs-NyjpwWWc",
        "outputId": "07fe0d0d-67d2-4d68-f2f1-5dd7ae5cb560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/bhavikjikadara/fake-news-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41.0M/41.0M [00:00<00:00, 114MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Configure Kaggle API credentials\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset using Kaggle API\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"bhavikjikadara/fake-news-detection\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIVf0h8Q23d6",
        "outputId": "91444af7-00ec-40cd-b55e-964c4aed79e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/bhavikjikadara/fake-news-detection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load true and fake news datasets\n",
        "true_df = pd.read_csv('true.csv')\n",
        "fake_df = pd.read_csv('fake.csv')"
      ],
      "metadata": {
        "id": "g4gzuBpJwhnT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing abbreviation to have a uniform format for dates\n",
        "mois = {\n",
        "    'Jan ': 'January ',\n",
        "    'Feb ': 'February ',\n",
        "    'Mar ': 'March ',\n",
        "    'Apr ': 'April ',\n",
        "    'May ': 'May ',\n",
        "    'Jun ': 'June ',\n",
        "    'Jul ': 'July ',\n",
        "    'Aug ': 'August ',\n",
        "    'Sep ': 'September ',\n",
        "    'Oct ': 'October ',\n",
        "    'Nov ': 'November ',\n",
        "    'Dec ': 'December '\n",
        "}\n",
        "fake_df['date'] = fake_df['date'].replace(mois, regex=True)\n",
        "\n",
        "# Converting dates to Date variables\n",
        "true_df['date'] = pd.to_datetime(true_df['date'], errors='coerce')\n",
        "fake_df['date'] = pd.to_datetime(fake_df['date'], errors='coerce')\n",
        "\n",
        "print(true_df['date'].sample(10))\n",
        "print(fake_df['date'].sample(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRSjh24Oxd8J",
        "outputId": "99d44dfd-43a7-4a68-a93f-2b36b5d9da4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14813   2017-11-14\n",
            "3499    2017-05-31\n",
            "5993    2017-01-26\n",
            "13391   2017-11-30\n",
            "7908    2016-10-07\n",
            "5579    2017-02-08\n",
            "10011   2016-04-08\n",
            "20339   2017-09-12\n",
            "9353    2016-05-28\n",
            "10112   2016-03-31\n",
            "Name: date, dtype: datetime64[ns]\n",
            "15101   2015-10-11\n",
            "10015   2017-08-29\n",
            "23029   2017-01-27\n",
            "10391   2017-07-16\n",
            "844     2017-07-16\n",
            "19646   2016-11-11\n",
            "12173   2016-12-11\n",
            "12588   2016-10-28\n",
            "12048   2016-12-28\n",
            "12137   2016-12-15\n",
            "Name: date, dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a label column: 1 for true news, 0 for fake news\n",
        "true_df['label'] = 1\n",
        "fake_df['label'] = 0\n",
        "\n",
        "# Combine both datasets into a single DataFrame\n",
        "df = pd.concat([true_df, fake_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "UBm7L4iDx_-q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Date column**"
      ],
      "metadata": {
        "id": "pAV4pc0k_2ss"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjT-UyefC8Wz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Subject column**"
      ],
      "metadata": {
        "id": "LpbbKp6cAPSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the 'subject' column across datasets\n",
        "subject_mapping = {\n",
        "    'News': 'General News',\n",
        "    'US_News': 'General News',\n",
        "    'worldnews': 'General News',\n",
        "    'politics': 'Politics',\n",
        "    'politicsNews': 'Politics',\n",
        "    'left-news': 'Politics',\n",
        "    'Middle-east': 'General News',\n",
        "    'Government News': 'Politics'\n",
        "}\n",
        "df['subject'] = df['subject'].map(subject_mapping)\n",
        "\n",
        "# Drop the 'subject' column because it is not relevant for the analysis\n",
        "df = df.drop(columns=['subject'])"
      ],
      "metadata": {
        "id": "a6IC0THgx-3b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Feature engineering**"
      ],
      "metadata": {
        "id": "4a4y-pdhA2YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate uppercase letter percentage in text with rounding to 2 decimal places\n",
        "def calculate_uppercase_proportion(text):\n",
        "    if len(text) == 0:\n",
        "        return 0\n",
        "    uppercase_count = sum(1 for char in text if char.isupper())\n",
        "    percentage = (uppercase_count / len(text))\n",
        "    return round(percentage, 3)  # Round to two decimal places\n",
        "\n",
        "# Add a column for uppercase percentage in titles\n",
        "df['uppercase_proportion'] = df['title'].apply(calculate_uppercase_proportion)"
      ],
      "metadata": {
        "id": "uEQcnbw_zRZW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Title and Text columns**"
      ],
      "metadata": {
        "id": "r-hoYURRA8MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "idYEQ5ehQS1w",
        "outputId": "c243a2a7-89c7-4632-ecd1-cc850ba83161"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates from the combined DataFrame\n",
        "df.drop_duplicates(keep='first', inplace=True)"
      ],
      "metadata": {
        "id": "V929WELMFnnd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all text until \"(Reuters) - \" in the dataset\n",
        "df['text'] = df['text'].str.replace(r'^.*\\(Reuters\\) - ', '', regex=True)"
      ],
      "metadata": {
        "id": "pxLxJYfRFa1w"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to lowercase\n",
        "df['title'] = df['title'].str.lower()\n",
        "df['text'] = df['text'].str.lower()"
      ],
      "metadata": {
        "id": "CKDorsI7PYtF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace only '.' with '' in the 'text' column\n",
        "df['title'] = df['title'].str.replace(r'\\.', '', regex=True)\n",
        "df['text'] = df['text'].str.replace(r'\\.', '', regex=True)"
      ],
      "metadata": {
        "id": "DE-mJZosGwaf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure no NaN values in 'title' and 'text' before removing special characters\n",
        "df['title'] = df['title'].fillna('').str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)\n",
        "df['text'] = df['text'].fillna('').str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)"
      ],
      "metadata": {
        "id": "C7iZ3mRRFhX2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where 'title' or 'text' are empty strings\n",
        "df = df[(df['title'] != '') & (df['text'] != '')]"
      ],
      "metadata": {
        "id": "e1EvDiRbyzjD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "df['title'] = df['title'].apply(word_tokenize)\n",
        "df['text'] = df['text'].apply(word_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elTs8P9MzXP7",
        "outputId": "66b2cfda-80fb-47ed-e82d-6f166f6c033e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['title'] = df['title'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "df['text'] = df['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjs98AsTCrkK",
        "outputId": "7a6cfd9e-9357-42e2-ef6d-482c07dfbd1b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stop words\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['title'] = df['title'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stop_words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0t_Mh8SBZxZ",
        "outputId": "9272c54a-69ac-41ab-d84b-43972fe8cce9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_title = vectorizer.fit_transform(df['title'].apply(' '.join))\n",
        "X_text = vectorizer.fit_transform(df['text'].apply(' '.join))"
      ],
      "metadata": {
        "id": "hQYFQNjrKflv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. Training**"
      ],
      "metadata": {
        "id": "fxXnq1DPY6wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate X and Y\n",
        "X = hstack((X_title, X_text))\n",
        "Y = df['label']"
      ],
      "metadata": {
        "id": "znw_GVecYn1G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gfip4MB_Dg4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Train a classifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(\"Model accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkKfQ5WkZdoK",
        "outputId": "461e5d13-f409-4ff7-88e5-38519968f4d5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.9689337765277423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred, average='binary')  # Use 'binary' for binary classification\n",
        "# or if you have multi-class classification, use 'macro' or 'weighted'\n",
        "# f1 = f1_score(y_test, y_pred, average='macro')\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Model accuracy:\", clf.score(X_test, y_test))\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVoT6OhIbp7V",
        "outputId": "5e73438b-20c0-4677-95d9-1c5469c365f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.9689337765277423\n",
            "F1 Score: 0.9716816221885561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM classifier\n",
        "svm_clf = SVC()  # You can specify kernel='linear', 'rbf', etc., based on your needs\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "# Evaluate and print results\n",
        "accuracy = svm_clf.score(X_test, y_test)\n",
        "print(\"Model accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5S_EQ9G9DHB",
        "outputId": "70d71c3b-77e9-43d5-ce93-2a18113572ac"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.989516747634876\n",
            "F1 Score: 0.9903210576015109\n"
          ]
        }
      ]
    }
  ]
}